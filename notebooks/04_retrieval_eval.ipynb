{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Notebook 04 — Hybrid Retrieval (BM25 + FAISS) + Rerank\n",
    "Goal: BM25 keyword recall + dense E5 vectors → fuse → rerank with bge-reranker → soft filters by competition/topic/stage."
   ],
   "id": "516587a8575657d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load artifacts & models\n",
    "\n",
    "Purpose: load meta.parquet, FAISS index, E5 for queries, and optional reranker."
   ],
   "id": "df0e44fdc6cd347c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:44:36.089992Z",
     "start_time": "2025-08-14T20:44:01.273427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 0) Load index + models (single source of truth) ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch, faiss\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT = NOTEBOOK_DIR.parent\n",
    "INDEX_DIR  = ROOT / \"data\" / \"index\"\n",
    "META_PATH  = INDEX_DIR / \"meta.parquet\"\n",
    "FAISS_PATH = INDEX_DIR / \"faiss_e5.index\"\n",
    "\n",
    "assert META_PATH.exists() and FAISS_PATH.exists(), \"Run Notebook 03 first.\"\n",
    "\n",
    "meta = pd.read_parquet(META_PATH).reset_index(drop=True)\n",
    "index = faiss.read_index(str(FAISS_PATH))\n",
    "assert index.ntotal == len(meta), f\"FAISS size ({index.ntotal}) != meta rows ({len(meta)})\"\n",
    "\n",
    "# Models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "DEVICE  = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "E5_ID   = \"intfloat/multilingual-e5-base\"\n",
    "e5 = SentenceTransformer(E5_ID, device=DEVICE)\n",
    "\n",
    "# Optional reranker (safe fallback)\n",
    "try:\n",
    "    from FlagEmbedding import FlagReranker\n",
    "    # Force fp32; avoid MPS fp16\n",
    "    reranker = FlagReranker(\"BAAI/bge-reranker-v2-m3\", use_fp16=False)\n",
    "    HAVE_RERANKER = True\n",
    "except Exception as e:\n",
    "    print(\"Reranker unavailable → will skip rerank:\", e)\n",
    "    reranker = None\n",
    "    HAVE_RERANKER = False\n",
    "\n",
    "print(\"Loaded:\", len(meta), \"chunks | FAISS ntotal:\", index.ntotal)\n",
    "print(\"Device:\", DEVICE, \"| Reranker:\", HAVE_RERANKER)\n",
    "print(\"Meta columns:\", list(meta.columns)[:10], \"…\")"
   ],
   "id": "1a337c7182ab5845",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 137 chunks | FAISS ntotal: 137\n",
      "Device: mps | Reranker: True\n",
      "Meta columns: ['rid', 'qa_id', 'competition', 'topic', 'stage', 'page_start', 'page_end', 'chunk_type', 'content'] …\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build BM25 corpus (tokenize TR/EN)\n",
    "\n",
    "Purpose: keyword recall over all chunks."
   ],
   "id": "9b3f26c073b51d01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:44:36.444545Z",
     "start_time": "2025-08-14T20:44:36.429340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1) BM25 corpus ---\n",
    "from rank_bm25 import BM25Okapi\n",
    "import re\n",
    "\n",
    "def norm_tokenize(text: str):\n",
    "    # keep Turkish diacritics; split to word tokens\n",
    "    return re.findall(r\"[A-Za-z0-9ÇĞİÖŞÜçğıöşü]+\", text.lower())\n",
    "\n",
    "bm25_corpus = [norm_tokenize(s) for s in meta[\"content\"].astype(str).tolist()]\n",
    "bm25 = BM25Okapi(bm25_corpus)\n",
    "print(\"BM25 built over\", len(bm25_corpus), \"chunks\")"
   ],
   "id": "53e6d31b7fa1857",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 built over 137 chunks\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Router (synonyms + hint detection)\n",
    "\n",
    "Purpose: detect likely competition/topic/stage from the query text."
   ],
   "id": "e8ba2ff2d99c4ed9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:44:36.591242Z",
     "start_time": "2025-08-14T20:44:36.585888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 2) Router (soft hints for competition/topic/stage) ---\n",
    "import re\n",
    "\n",
    "SYN = {\n",
    "    \"competition\": {\n",
    "        \"HSS\":      [r\"hss\", r\"hava savunma\"],\n",
    "        \"E-TICARET\":[r\"e-?ticaret\", r\"e ticaret\", r\"hackathon\"],\n",
    "        \"ADRES\":    [r\"adres(?![a-z])\", r\"adres çöz\"],\n",
    "    },\n",
    "    \"topic\": {\n",
    "        \"timeline\":   [r\"son başvuru|başvuru tarihi|son tarih|takvim\"],\n",
    "        \"penalties\":  [r\"ceza|diskalifiye|ihlal|yasak|kural d[ıi]şı|dost (hedef|ateş[iı])|yanl[ıi]ş hedef\"],\n",
    "        \"scoring\":    [r\"puan|puanlama|bsp|kriter|bonus|kesinti|değerlendir\"],\n",
    "        \"team\":       [r\"tak[ıi]m|üye|danışman|ekip\"],\n",
    "        \"eligibility\":[r\"uygun|başvuru koşul|kimler|gereklilik|şart\"],\n",
    "        \"stages\":     [r\"aşama|görev|süreç|sunum\"],\n",
    "        \"logistics\":  [r\"konaklama|ulaşım|destek|mekan|sponsor\"],\n",
    "    },\n",
    "    \"stage\": {\n",
    "        1: [r\"\\b1(\\.|\\s|$)|\\bi\\b\"],\n",
    "        2: [r\"\\b2(\\.|\\s|$)|\\bii\\b\"],\n",
    "        3: [r\"\\b3(\\.|\\s|$)|\\biii\\b\"],\n",
    "    }\n",
    "}\n",
    "\n",
    "def route_query(q: str):\n",
    "    ql = q.lower()\n",
    "    comp = next((c for c,pats in SYN[\"competition\"].items() if any(re.search(p, ql) for p in pats)), None)\n",
    "    topic = next((t for t,pats in SYN[\"topic\"].items()       if any(re.search(p, ql) for p in pats)), None)\n",
    "    stage = next((s for s,pats in SYN[\"stage\"].items()       if any(re.search(p, ql) for p in pats)), None)\n",
    "    return {\"competition\": comp, \"topic\": topic, \"stage\": stage}"
   ],
   "id": "8da9b8b1fb54fb82",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Soft filters (apply only if they don’t zero-out results)\n",
    "\n",
    "Purpose: take candidate indices and keep only those matching competition/topic/stage if those values exist and filtering doesn’t wipe everything. Otherwise, fall back to the originals."
   ],
   "id": "df1076cf489735eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:44:36.698376Z",
     "start_time": "2025-08-14T20:44:36.693722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 3) Soft filters ---\n",
    "def supported_values(col, val):\n",
    "    if val is None:\n",
    "        return False\n",
    "    try:\n",
    "        return val in set(meta[col].dropna().unique())\n",
    "    except KeyError:\n",
    "        return False\n",
    "\n",
    "def apply_soft_filter(idxs, comp=None, topic=None, stage=None, want=None):\n",
    "    idxs = list(idxs)\n",
    "    if not idxs:\n",
    "        return idxs\n",
    "\n",
    "    orig = idxs[:]\n",
    "\n",
    "    # competition\n",
    "    if comp and supported_values(\"competition\", comp):\n",
    "        kept = [i for i in idxs if meta.loc[i, \"competition\"] == comp]\n",
    "        idxs = kept or orig\n",
    "\n",
    "    # topic (with penalties fallback)\n",
    "    if topic:\n",
    "        if supported_values(\"topic\", topic):\n",
    "            kept = [i for i in idxs if meta.loc[i, \"topic\"] == topic]\n",
    "            if not kept and topic == \"penalties\":\n",
    "                # label exists globally but none in this candidate set → content fallback\n",
    "                import re\n",
    "                pat = re.compile(r\"ceza|diskalifiye|yanl[ıi]ş hedef|dost hedef\", re.IGNORECASE)\n",
    "                kept = [i for i in idxs if pat.search(str(meta.loc[i, \"content\"]))]\n",
    "\n",
    "            idxs = kept or idxs\n",
    "        else:\n",
    "            # label missing globally → content fallback only for penalties\n",
    "            if topic == \"penalties\":\n",
    "                import re\n",
    "                pat = re.compile(r\"ceza|diskalifiye|yanl[ıi]ş hedef|dost hedef\", re.IGNORECASE)\n",
    "                kept = [i for i in idxs if pat.search(str(meta.loc[i, \"content\"]))]\n",
    "                if kept:\n",
    "                    idxs = kept\n",
    "\n",
    "    # stage\n",
    "    if stage and supported_values(\"stage\", stage):\n",
    "        kept = [i for i in idxs if meta.loc[i, \"stage\"] == stage]\n",
    "        idxs = kept or idxs\n",
    "\n",
    "    if want:\n",
    "        idxs = idxs[:want]\n",
    "    return idxs"
   ],
   "id": "e7505d0842b3ed65",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Search primitives (FAISS dense + BM25 keyword)\n",
    "Purpose: helpers to get top-K candidates from each retriever, safely handling edge cases."
   ],
   "id": "5b9a32006221e7f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:44:36.715977Z",
     "start_time": "2025-08-14T20:44:36.712220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 4) Search primitives ---\n",
    "def faiss_search(q: str, top_k=60):\n",
    "    \"\"\"Dense search with E5; returns (scores, indices).\"\"\"\n",
    "    qvec = e5.encode([\"query: \" + q], normalize_embeddings=True).astype(\"float32\")\n",
    "    D, I = index.search(qvec, min(top_k, index.ntotal))\n",
    "    return D[0], I[0]\n",
    "\n",
    "def bm25_search(q: str, top_k=60):\n",
    "    \"\"\"Keyword search with BM25; returns (scores, indices).\"\"\"\n",
    "    toks = norm_tokenize(q)\n",
    "    scores = bm25.get_scores(toks)  # numpy array, len = corpus size\n",
    "    n = len(scores)\n",
    "    k = min(top_k, n)\n",
    "    if k == n:\n",
    "        top_idx = np.argsort(scores)[::-1]\n",
    "    else:\n",
    "        part = np.argpartition(scores, -k)[-k:]\n",
    "        top_idx = part[np.argsort(scores[part])[::-1]]\n",
    "    return scores[top_idx], top_idx"
   ],
   "id": "f8b9b2944159b935",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Hybrid fusion + (optional) rerank\n",
    "\n",
    "Purpose: union dense + bm25 (after soft filters), normalize to [0,1], fuse with weights, then rerank with bge-reranker-v2-m3 if available."
   ],
   "id": "ac9361324a5beee4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:44:36.741216Z",
     "start_time": "2025-08-14T20:44:36.729063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 5) Hybrid search (soft filters + fusion + (optional) rerank) ---\n",
    "def hybrid_search(query, bm25_k=60, dense_k=60, rerank_k=10, weights=(0.75, 0.25)):\n",
    "    route = route_query(query)\n",
    "    comp, topic, stage = route[\"competition\"], route[\"topic\"], route[\"stage\"]\n",
    "\n",
    "    # Dense search → zip → soft-filter (keep score/index alignment)\n",
    "    d_scores, d_idx = faiss_search(query, top_k=dense_k)\n",
    "    d_pairs_all = list(zip(d_idx.tolist(), d_scores.tolist()))\n",
    "    d_keep = apply_soft_filter([i for i,_ in d_pairs_all], comp, topic, stage, want=dense_k)\n",
    "    d_set = set(d_keep)\n",
    "    d_pairs = [(i, s) for (i, s) in d_pairs_all if i in d_set]\n",
    "    d_map = {i: float(s) for (i, s) in d_pairs}\n",
    "\n",
    "    # BM25 search → zip → soft-filter (keep score/index alignment)\n",
    "    b_scores, b_idx = bm25_search(query, top_k=bm25_k)\n",
    "    b_pairs_all = list(zip(b_idx.tolist(), b_scores.tolist()))\n",
    "    b_keep = apply_soft_filter([i for i,_ in b_pairs_all], comp, topic, stage, want=bm25_k)\n",
    "    b_set = set(b_keep)\n",
    "    b_pairs = [(i, s) for (i, s) in b_pairs_all if i in b_set]\n",
    "    b_map = {i: float(s) for (i, s) in b_pairs}\n",
    "\n",
    "    # Normalize each modality to [0,1]\n",
    "    def _norm_map(m):\n",
    "        if not m: return {}\n",
    "        vals = np.array(list(m.values()), dtype=float)\n",
    "        lo, hi = float(vals.min()), float(vals.max())\n",
    "        if hi <= lo:  # constant\n",
    "            return {k: 0.0 for k in m}\n",
    "        return {k: (v - lo) / (hi - lo) for k,v in m.items()}\n",
    "\n",
    "    d_norm = _norm_map(d_map)\n",
    "    b_norm = _norm_map(b_map)\n",
    "\n",
    "    # Fuse (weighted sum)\n",
    "    fused = {}\n",
    "    for i, s in d_norm.items():\n",
    "        fused[i] = fused.get(i, 0.0) + weights[1] * s\n",
    "    for i, s in b_norm.items():\n",
    "        fused[i] = fused.get(i, 0.0) + weights[0] * s\n",
    "    if not fused:\n",
    "        return [], route\n",
    "\n",
    "    # Tiny feature bonus (penalties / dates / team size)\n",
    "    import re\n",
    "    MONTHS = \"ocak|şubat|subat|mart|nisan|mayıs|mayis|haziran|temmuz|ağustos|agustos|eylül|eylul|ekim|kasım|kasim|aralık|aralik\"\n",
    "    DATE_RE = re.compile(rf\"\\b\\d{{1,2}}[./]\\d{{1,2}}[./]\\d{{4}}\\b|({MONTHS})\", re.IGNORECASE)\n",
    "\n",
    "    def _bonus(i: int, ql: str) -> float:\n",
    "        text = str(meta.loc[i, \"content\"]).lower()\n",
    "        ctype = meta.loc[i, \"chunk_type\"]\n",
    "        b = 0.0\n",
    "        if re.search(r\"ceza|penalt|diskalifiye|yanl[ıi]ş hedef|dost hedef\", ql):\n",
    "            if re.search(r\"ceza|diskalifiye|puan\", text): b += 0.15\n",
    "        if re.search(r\"son başvuru|başvuru tarihi|deadline|tarih|takvim\", ql):\n",
    "            if DATE_RE.search(text): b += 0.15\n",
    "            if ctype == \"limits\":   b += 0.05\n",
    "        if re.search(r\"kaç kişi|kaç kis|kaç üye|takım sayısı|ekip sayısı\", ql):\n",
    "            if re.search(r\"\\b(kişi|üye)\\b\", text) and re.search(r\"\\b\\d+\\b\", text): b += 0.12\n",
    "            if ctype == \"limits\": b += 0.05\n",
    "        return b\n",
    "\n",
    "    ql = query.lower()\n",
    "    for i in list(fused.keys()):\n",
    "        fused[i] += _bonus(i, ql)\n",
    "\n",
    "    # Prelim list for rerank\n",
    "    prelim = sorted(fused.items(), key=lambda x: x[1], reverse=True)[:max(3*rerank_k, rerank_k)]\n",
    "    prelim_ids = [i for i,_ in prelim]\n",
    "\n",
    "    # Rerank (if available)\n",
    "    if HAVE_RERANKER:\n",
    "        pairs = [(query, meta.loc[i, \"content\"]) for i in prelim_ids]\n",
    "        if not pairs:\n",
    "            return [], route\n",
    "        scores = reranker.compute_score(pairs, normalize=True, max_length=512)\n",
    "        pairs_scored = list(zip(prelim_ids, scores))\n",
    "\n",
    "        if route.get(\"topic\") == \"penalties\":\n",
    "            import re\n",
    "            pen_re   = re.compile(r\"ceza|diskalifiye|yanl[ıi]ş hedef|dost hedef\", re.IGNORECASE)\n",
    "            strong_re= re.compile(r\"-\\\\s*30|yanl[ıi]ş hedef\", re.IGNORECASE)  # stronger hints\n",
    "            bsp_re   = re.compile(r\"\\\\bbsp\\\\b\", re.IGNORECASE)\n",
    "\n",
    "            bumped = []\n",
    "            for i, s in pairs_scored:\n",
    "                text  = str(meta.loc[i, \"content\"]).lower()\n",
    "                bonus = 0.0\n",
    "                if pen_re.search(text):     bonus += 0.04   # was 0.02\n",
    "                if strong_re.search(text):  bonus += 0.03   # extra for “-30” / “yanlış hedef”\n",
    "                if bsp_re.search(text):     bonus -= 0.03   # tiny down-bump for BSP in a penalties query\n",
    "                bumped.append((i, float(s + bonus)))\n",
    "        else:\n",
    "            bumped = [(i, float(s)) for i, s in pairs_scored]\n",
    "\n",
    "        # de-dup by qa_id; prefer 'qa' over 'limits'/'formula'\n",
    "        def _ctype_pref(i: int) -> int:\n",
    "            return {\"qa\": 2, \"limits\": 1, \"formula\": 0}.get(meta.loc[i, \"chunk_type\"], 0)\n",
    "\n",
    "        best_by_qid = {}\n",
    "        for i, s in bumped:\n",
    "            qid = meta.loc[i, \"qa_id\"]\n",
    "            prev = best_by_qid.get(qid)\n",
    "            if prev is None or s > prev[1] + 1e-9 or (abs(s - prev[1]) < 1e-9 and _ctype_pref(i) > _ctype_pref(prev[0])):\n",
    "                best_by_qid[qid] = (i, s)\n",
    "\n",
    "        ranked = sorted(best_by_qid.values(), key=lambda x: x[1], reverse=True)[:rerank_k]\n",
    "        return ranked, route\n",
    "\n",
    "    # Fallback: fused order\n",
    "    return [(i, s) for i, s in prelim[:rerank_k]], route"
   ],
   "id": "9e7704a3fa1c3b28",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pretty printer (compact, RAG-friendly)\n",
    "Purpose: print top hits with useful source tags."
   ],
   "id": "82c9178eb625e925"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:44:36.785447Z",
     "start_time": "2025-08-14T20:44:36.782769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 6) Pretty print results ---\n",
    "def show_results(query, results, max_chars=200):\n",
    "    print(\"\\nQ:\", query)\n",
    "    if not results:\n",
    "        print(\"  (no candidates)\")\n",
    "        return\n",
    "    for rank, (i, sc) in enumerate(results, 1):\n",
    "        row = meta.loc[i]\n",
    "        snippet = row[\"content\"].replace(\"\\n\", \" \")\n",
    "        print(f\"{rank:>2}. [{row['qa_id']} | {row['competition']} | {row['topic']} \"\n",
    "              f\"| p{int(row['page_start'])}-{int(row['page_end'])} | {row['chunk_type']}]\")\n",
    "        print(\"    score:\", f\"{float(sc):.3f}\")\n",
    "        print(\"    \", (snippet[:max_chars] + (\"…\" if len(snippet) > max_chars else \"\")))"
   ],
   "id": "9c2aa24b4c5f5817",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Basic sanity queries (TR + EN)\n",
    "Purpose: ensure end-to-end retrieval works and results look sensible."
   ],
   "id": "674d22699dfa199"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T20:45:17.669827Z",
     "start_time": "2025-08-14T20:44:36.852523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 7) Quick sanity tests (TR only) ---\n",
    "tests = [\n",
    "    \"HSS dost hedef vurma cezası nedir?\",\n",
    "    \"E-Ticaret için son başvuru tarihi\",\n",
    "    \"HSS BSP formülü nedir?\",\n",
    "    \"Adres yarışmasında takım kaç kişi olmalı?\",\n",
    "]\n",
    "\n",
    "for q in tests:\n",
    "    ranked, route = hybrid_search(q, bm25_k=60, dense_k=60, rerank_k=8)\n",
    "    print(\"route:\", route)\n",
    "    show_results(q, ranked, max_chars=180)"
   ],
   "id": "2b1fc2601dc6cc8f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "route: {'competition': 'HSS', 'topic': 'penalties', 'stage': None}\n",
      "\n",
      "Q: HSS dost hedef vurma cezası nedir?\n",
      " 1. [HSS-Q003 | HSS | eligibility | p9-14 | qa]\n",
      "    score: 1.055\n",
      "     Q: Hava Savunma Sistemleri Yarışması'nda yer alan \"Bonus Süre Puanı\" (BSP) A: mekanizmasının amacı nedir ve hangi koşullarda takımlara avantaj sağlamaktadır? Bu  puanın toplam sıra…\n",
      " 2. [HSS-Q028 | HSS | team | p5-5 | qa]\n",
      "    score: 1.022\n",
      "     Q: 2. Aşamada dost b+r hedef+ vurmanın cezası ned+r A: Tek b+r dost hedef+ vurmak -30 puanlık b+r ceza +le sonuçlanır. Eğer b+r takım +k+ veya daha  fazla dost hedef vurursa görev+…\n",
      "route: {'competition': 'E-TICARET', 'topic': 'timeline', 'stage': None}\n",
      "\n",
      "Q: E-Ticaret için son başvuru tarihi\n",
      " 1. [E-TICARET-QG002 | E-TICARET | team | p16-17 | qa]\n",
      "    score: 0.090\n",
      "     Q: sürecine ne gibi bir şe`aﬂık ve derinlik katmaktadır? A: Projelerin, sunumların başlayacağı 14 Eylül Pazar saat 14:00'e kadar Github'a yüklenmiş  olması zorunluluğu60, değerlend…\n",
      " 2. [E-TICARET-QG001 | E-TICARET | eligibility | p16-16 | qa]\n",
      "    score: 0.032\n",
      "     Q: önemi nedir? Bu süre takımlara ne gibi avantajlar sağlar? A: E-Ticaret Hackathonu takviminde, ﬁnalistlerin açıklanması ile ﬁziksel etkinliğin başlaması  arasında yaklaşık 15 gün…\n",
      " 3. [E-TICARET-QG003 | E-TICARET | eligibility | p17-17 | qa]\n",
      "    score: 0.008\n",
      "     Q: edilmesini gerektirir? A: E-Ticaret Hackathonu şartnamesinde, ﬁnale kalan takımlara sağlanacak ulaşım ve  konaklama desteğinin sınırlı olduğunun belirtilmesi, yarışmanın lojisti…\n",
      " 4. [E-TICARET-QG005 | E-TICARET | eligibility | p18-18 | qa]\n",
      "    score: 0.004\n",
      "     Q: takımlarına kıyasla lise takımları için neden daha kritik olarak görülmektedir? A: E-Ticaret Hackathonu şartnamesinde lise takımları için danışman bulundurma zorunluluğu  ve 18 …\n",
      " 5. [E-TICARET-QG004 | E-TICARET | team | p17-18 | limits]\n",
      "    score: 0.003\n",
      "     10; 3\n",
      " 6. [E-TICARET-QG006 | E-TICARET | team | p18-18 | qa]\n",
      "    score: 0.000\n",
      "     Q: teknoloji ve metodolojiler nasıl farklılaşmaktadır? A: E-Ticaret Hackathonu'nun iki aşaması, takımları farklı teknoloji ve metodolojileri  kullanmaya yönlendirecek şekilde kurgu…\n",
      "route: {'competition': 'HSS', 'topic': 'scoring', 'stage': None}\n",
      "\n",
      "Q: HSS BSP formülü nedir?\n",
      " 1. [HSS-Q003 | HSS | scoring | p9-14 | formula]\n",
      "    score: 0.930\n",
      "     Formula: \"Bonus Süre Puanı\" (BSP), Hava Savunma Sistemleri yarışmasının her üç görev aşamasında\n",
      "route: {'competition': 'ADRES', 'topic': 'team', 'stage': None}\n",
      "\n",
      "Q: Adres yarışmasında takım kaç kişi olmalı?\n",
      " 1. [ADRES-QG025 | ADRES | team | p23-23 | qa]\n",
      "    score: 0.026\n",
      "     Q: Finalist takımlara ulaşım ve konaklama desteği sağlanacak mı? A: Finale kalan takımlara sınırlı ulaşım ve konaklama desteği sağlanacaktır. Destek verilecek  kişi sayısı takım ba…\n",
      " 2. [ADRES-QG021 | ADRES | team | p22-22 | qa]\n",
      "    score: 0.004\n",
      "     Q: Yarışma süreci hakkında bilgilendirmeler nasıl yapılmaktadır? A: Yarışma süreci boyunca TEKNOFEST yarışmalar komitesi tarafından yapılacak tüm  bilgilendirmeler, takımın iletişi…\n",
      " 3. [ADRES-QG035 | ADRES | team | p25-25 | qa]\n",
      "    score: 0.003\n",
      "     Q: kriteri nasıl etkiler? A: Bu cevap, \"İş Birliği ve Ekip Dinamiği\" kriteri açısından takımı olumsuz etkiler. Bu kriter,  \"ekip üyeleri arasındaki görev dağılımı, teknik katkı den…\n",
      " 4. [ADRES-QG022 | ADRES | team | p22-22 | qa]\n",
      "    score: 0.002\n",
      "     Q: Takım üyeleri başka bir takımda veya birden fazla projeyle yarışmaya katılabilir mi? A: Hayır, bir kişi aynı yarışmada birden fazla takımda yer alamaz ve bir takım da birden faz…\n",
      " 5. [ADRES-QG014 | ADRES | team | p21-21 | qa]\n",
      "    score: 0.002\n",
      "     Q: Yarışmada ne gibi ödüller bulunmaktadır? A: Yarışmada ilk üçe giren takımlara nakdi para ödülü verilecektir. Birincilik ödülü 120.000,00  TL, ikincilik ödülü 100.000,00 TL ve üç…\n",
      " 6. [ADRES-QG006 | ADRES | team | p20-20 | qa]\n",
      "    score: 0.001\n",
      "     Q: Yarışma kaç aşamadan oluşmaktadır? A: Yarışma, iki ana aşamadan oluşmaktadır. Bu aşamalar, Ön Değerlendirme Aşaması ve  Uygulama Geliştirme Aşamasıdır. Bu süreç, takımların tekn…\n",
      " 7. [ADRES-QG009 | ADRES | team | p20-20 | qa]\n",
      "    score: 0.001\n",
      "     Q: Uygulama geliştirme aşamasında takımlardan ne beklenmektedir? A: Uygulama geliştirme aşamasında seçilen takımlar, sağlanan gerçek adres veri setini  kullanarak çalışan bir çözüm…\n",
      " 8. [ADRES-QG030 | ADRES | team | p23-24 | qa]\n",
      "    score: 0.001\n",
      "     Q: Yarışmaya katılan takımlardan geliştirilen çözümlerle ilgili ne istenmektedir? A: Geliştirilen çözümlerde, servis edilen model ve yaklaşımların kaynak koduna ve ağırlıklarına  e…\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
