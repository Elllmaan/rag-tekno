{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Goal: Extract PDF text with page refs, detect competition boundaries, and persist raw artifacts.",
   "id": "8bedf3d4c4cfbf04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports & paths",
   "id": "5199f9f72420b7ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:00:54.281860Z",
     "start_time": "2025-08-14T11:00:54.274040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 0) Imports & paths ---\n",
    "from pathlib import Path\n",
    "import re, json\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT = NOTEBOOK_DIR.parent\n",
    "\n",
    "PDF_PATH = ROOT / \"data/raw/rag-example-qa.pdf\"\n",
    "OUT_DIR = ROOT / \"data/processed\"\n",
    "(OUT_DIR / \"md\").mkdir(parents=True, exist_ok=True)\n",
    "(OUT_DIR / \"jsonl\").mkdir(parents=True, exist_ok=True)\n",
    "(OUT_DIR / \"csv\").mkdir(parents=True, exist_ok=True)"
   ],
   "id": "697da96190f4b79d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Extract text **with page numbers**\n",
    "\n",
    "- Use **PyMuPDF (fitz)** to iterate pages.\n",
    "\n",
    "- Store a list of dicts: `{\"page\": 1, \"text\": \"...raw page text...\"}`.\n",
    "\n",
    "- Save to `data/processed/page_dump.parquet` (or JSONL) for traceability."
   ],
   "id": "756f86dffa857e27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:00:56.622368Z",
     "start_time": "2025-08-14T11:00:56.522666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1) Extract text page-by-page ---\n",
    "def extract_pages(pdf_path: Path):\n",
    "    pages = []\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        for i, page in enumerate(doc, start=1):\n",
    "            text = page.get_text(\"text\")  # preserves reading order reasonably\n",
    "            pages.append({\"page\": i, \"text\": text})\n",
    "    return pages\n",
    "\n",
    "pages = extract_pages(PDF_PATH)\n",
    "len(pages), pages[0][\"page\"], pages[0][\"text\"][:300]"
   ],
   "id": "1964c74c5e2a8527",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,\n",
       " 1,\n",
       " \"Hava Savunma S)stemler) Yarışması \\n1. Hava Savunma S+stemler+ Yarışması'nın temel amacı ned+r? \\nYarışmanın amacı, takımların ver+len senaryolara uygun görevler+ başarıyla yer+ne get+recek \\nhava savunma s+stemler+ gel+şt+rmes+ ve üretmes+d+r. Aynı zamanda, hava savunma \\ns+stemler+n+n önem+n+n ülke ça\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:22:58.683417Z",
     "start_time": "2025-08-14T11:22:58.622556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# QUICK CHECK: page count, empty pages, sample preview\n",
    "import statistics as stats\n",
    "\n",
    "assert len(pages) > 0, \"No pages extracted.\"\n",
    "lengths = [len(p[\"text\"]) for p in pages]\n",
    "print(f\"Pages: {len(pages)} | avg chars/page: {int(stats.mean(lengths))} | min: {min(lengths)} | max: {max(lengths)}\")\n",
    "empties = [p[\"page\"] for p in pages if len(p[\"text\"].strip()) == 0]\n",
    "print(\"Empty pages:\", empties[:5], \"...\" if len(empties) > 5 else \"\")\n",
    "print(\"Preview p1:\\n\", pages[0][\"text\"][:400])"
   ],
   "id": "383175d43dac106b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages: 28 | avg chars/page: 2324 | min: 1475 | max: 3035\n",
      "Empty pages: [] \n",
      "Preview p1:\n",
      " Hava Savunma S)stemler) Yarışması \n",
      "1. Hava Savunma S+stemler+ Yarışması'nın temel amacı ned+r? \n",
      "Yarışmanın amacı, takımların ver+len senaryolara uygun görevler+ başarıyla yer+ne get+recek \n",
      "hava savunma s+stemler+ gel+şt+rmes+ ve üretmes+d+r. Aynı zamanda, hava savunma \n",
      "s+stemler+n+n önem+n+n ülke çapında gen+ş b+r tabana yayılarak özgün, yerl+ ve yetenekl+ \n",
      "s+stemler+n gel+şt+r+lmes+n+ sağlamak da\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Quick section boundary detection (competition names)\n",
    "\n",
    "- Scan each page’s text for any of these **anchors** (case-insensitive):\n",
    "\n",
    "    - `Hava Savunma Sistemleri`\n",
    "\n",
    "    - `E-Ticaret Hackathonu`\n",
    "\n",
    "    - `Yapay Zeka Destekli Adres Çözümleme`\n",
    "\n",
    "- Create a `page → competition` map by “last seen anchor wins”.\n",
    "\n",
    "- Save to `data/processed/page_sections.parquet`."
   ],
   "id": "fde4c57f98a5c6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:24:01.378726Z",
     "start_time": "2025-08-14T11:24:01.363367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 2) Detect competition per page via simple anchors ---\n",
    "# Canonical names and short codes\n",
    "COMP_NAMES = {\n",
    "    \"hava savunma sistemleri\": \"HSS\",\n",
    "    \"e-ticaret hackathonu\": \"E-TICARET\",\n",
    "    \"yapay zeka destekli adres çözümleme\": \"ADRES\",\n",
    "}\n",
    "\n",
    "def detect_competitions(pages):\n",
    "    last_seen = None\n",
    "    comp_by_page = {}\n",
    "    for p in pages:\n",
    "        t_low = p[\"text\"].casefold()\n",
    "        found = None\n",
    "        for anchor, code in COMP_NAMES.items():\n",
    "            if anchor in t_low:\n",
    "                found = code\n",
    "                break\n",
    "        last_seen = found or last_seen\n",
    "        comp_by_page[p[\"page\"]] = last_seen  # may be None initially\n",
    "    # Forward/back fill if any None remain\n",
    "    # Back-fill from next known, then forward-fill from previous known\n",
    "    keys = sorted(comp_by_page)\n",
    "    # back-fill\n",
    "    next_seen = None\n",
    "    for k in reversed(keys):\n",
    "        if comp_by_page[k] is None and next_seen is not None:\n",
    "            comp_by_page[k] = next_seen\n",
    "        elif comp_by_page[k] is not None:\n",
    "            next_seen = comp_by_page[k]\n",
    "    # forward-fill\n",
    "    prev_seen = None\n",
    "    for k in keys:\n",
    "        if comp_by_page[k] is None and prev_seen is not None:\n",
    "            comp_by_page[k] = prev_seen\n",
    "        elif comp_by_page[k] is not None:\n",
    "            prev_seen = comp_by_page[k]\n",
    "    return comp_by_page\n",
    "\n",
    "comp_by_page = detect_competitions(pages)\n",
    "pd.DataFrame({\"page\":[p[\"page\"] for p in pages], \"competition\":[comp_by_page[p[\"page\"]] for p in pages]}).head(28)\n"
   ],
   "id": "b3da48bb1231f3c4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    page competition\n",
       "0      1         HSS\n",
       "1      2         HSS\n",
       "2      3         HSS\n",
       "3      4         HSS\n",
       "4      5         HSS\n",
       "5      6         HSS\n",
       "6      7         HSS\n",
       "7      8         HSS\n",
       "8      9         HSS\n",
       "9     10         HSS\n",
       "10    11         HSS\n",
       "11    12         HSS\n",
       "12    13         HSS\n",
       "13    14         HSS\n",
       "14    15   E-TICARET\n",
       "15    16   E-TICARET\n",
       "16    17   E-TICARET\n",
       "17    18   E-TICARET\n",
       "18    19       ADRES\n",
       "19    20       ADRES\n",
       "20    21       ADRES\n",
       "21    22       ADRES\n",
       "22    23       ADRES\n",
       "23    24       ADRES\n",
       "24    25       ADRES\n",
       "25    26       ADRES\n",
       "26    27       ADRES\n",
       "27    28       ADRES"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>competition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>HSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>HSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>HSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>HSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>HSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>HSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>HSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>HSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>HSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>HSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>HSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>E-TICARET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>E-TICARET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>E-TICARET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>E-TICARET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>ADRES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>ADRES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>ADRES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>ADRES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>ADRES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>ADRES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>ADRES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>ADRES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>ADRES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>ADRES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:02:28.995354Z",
     "start_time": "2025-08-14T11:02:28.978495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 3) Save raw JSONL dump and page→competition map ---\n",
    "# JSONL: one line per page {page, text}\n",
    "with open(OUT_DIR / \"page_dump.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for p in pages:\n",
    "        f.write(json.dumps(p, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# CSV map\n",
    "pd.DataFrame([\n",
    "    {\"page\": p[\"page\"], \"competition\": comp_by_page[p[\"page\"]]}\n",
    "    for p in pages\n",
    "]).to_csv(OUT_DIR / \"page_sections.csv\", index=False)\n"
   ],
   "id": "4824c94f902cc3db",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:24:19.206157Z",
     "start_time": "2025-08-14T11:24:19.199478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# FILE CHECK: artifacts exist and are non-empty\n",
    "for p in [OUT_DIR / \"page_dump.jsonl\", OUT_DIR / \"page_sections.csv\"]:\n",
    "    assert p.exists() and p.stat().st_size > 0, f\"Missing or empty: {p}\"\n",
    "print(\"Saved:\", (OUT_DIR / \"page_dump.jsonl\"), (OUT_DIR / \"page_sections.csv\"))\n"
   ],
   "id": "b4e397982b0df92b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/macbook/T3/rag-tekno/data/processed/page_dump.jsonl /Users/macbook/T3/rag-tekno/data/processed/page_sections.csv\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Persist a raw, linearized dump (optional but handy)\n",
    "\n",
    "- Concatenate pages into a single text with clear separators:\n",
    "\n",
    "    ```\n",
    "    === PAGE 1 (HSS) ===\n",
    "    ...text...\n",
    "    === PAGE 2 (HSS) ===\n",
    "    ```\n",
    "\n",
    "- Save as `data/processed/md/raw_linearized.md` for quick greps later."
   ],
   "id": "3e8129d730f45a99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:04:18.602543Z",
     "start_time": "2025-08-14T11:04:18.578910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 4) Linearized Markdown (handy for quick manual checks/greps) ---\n",
    "linear_md = []\n",
    "for p in pages:\n",
    "    comp = comp_by_page[p[\"page\"]] or \"UNKNOWN\"\n",
    "    linear_md.append(f\"=== PAGE {p['page']} ({comp}) ===\\n{p['text'].rstrip()}\\n\\n\")\n",
    "(Path(OUT_DIR / \"md\") / \"raw_linearized.md\").write_text(\"\".join(linear_md), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Ingest complete →\",\n",
    "      \"\\n- data/processed/page_dump.jsonl\",\n",
    "      \"\\n- data/processed/page_sections.csv\",\n",
    "      \"\\n- data/processed/md/raw_linearized.md\")\n"
   ],
   "id": "435c442385fe294b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingest complete → \n",
      "- data/processed/page_dump.jsonl \n",
      "- data/processed/page_sections.csv \n",
      "- data/processed/md/raw_linearized.md\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "50e7cfa2f8483881"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
